{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled50.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMOWkP23sSPrNfw1vne0T8C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkurbatovv/Python/blob/main/Random_Forest_and_Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_i_Fs_c4u8s"
      },
      "outputs": [],
      "source": [
        "# Packages / libraries\n",
        "import os #provides functions for interacting with the operating system\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# To install sklearn type \"pip install numpy scipy scikit-learn\" to the anaconda terminal\n",
        "\n",
        "# To change scientific numbers to float\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
        "\n",
        "# Increases the size of sns plots\n",
        "sns.set(rc={'figure.figsize':(8,6)})\n",
        "\n",
        "# Datetime lib\n",
        "from pandas import to_datetime\n",
        "import itertools\n",
        "import warnings\n",
        "import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('churn raw data.csv')"
      ],
      "metadata": {
        "id": "33qrsp6e6U1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.shape"
      ],
      "metadata": {
        "id": "TFIzmPZx667p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.head()"
      ],
      "metadata": {
        "id": "DydtBMjO68TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in raw_data:\n",
        "    unique_vals = np.unique(raw_data[column])\n",
        "    nr_values = len(unique_vals)\n",
        "    if nr_values < 12:\n",
        "        print('The number of values for feature {} :{} -- {}'.format(column, nr_values,unique_vals))\n",
        "    else:\n",
        "        print('The number of values for feature {} :{}'.format(column, nr_values))"
      ],
      "metadata": {
        "id": "gzD_z7Cq69rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.columns"
      ],
      "metadata": {
        "id": "XCPtRnI8_nWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data2 = raw_data[['CreditScore', 'Geography',\n",
        "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
        "       'IsActiveMember', 'EstimatedSalary', 'Exited']]"
      ],
      "metadata": {
        "id": "niZtK43w_pu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#g = sns.pairplot(raw_data2, hue='Exited', diag_kws={'bw': 0.2})"
      ],
      "metadata": {
        "id": "yvREV28e_5lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Geography', 'Gender', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard',\n",
        "       'IsActiveMember']\n"
      ],
      "metadata": {
        "id": "mif4JSkcAFTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in features:\n",
        "  plt.figure(figsize=(12,8))\n",
        "  ax = sns.countplot(x=f, data=raw_data2, hue='Exited', palette='Set1')"
      ],
      "metadata": {
        "id": "BVI-Y3NMF5S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_raw_data = pd.get_dummies(raw_data2, columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember'])\n",
        "new_raw_data.head()"
      ],
      "metadata": {
        "id": "lVm96cfzGOWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_val = ['CreditScore',\t'Age', 'Balance', 'EstimatedSalary']\n",
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "FnKO84uhKHsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_raw_data[scaler_val] = scaler.fit_transform(new_raw_data[scaler_val])"
      ],
      "metadata": {
        "id": "p4qnWXLxPw8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_raw_data.head()"
      ],
      "metadata": {
        "id": "wQO_Ixa5P-lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = new_raw_data.drop('Exited', axis=1).values# Input features (attributes)\n",
        "y = new_raw_data['Exited'].values # Target vector\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 0)"
      ],
      "metadata": {
        "id": "1OeNtmhEQB3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "GNWtKrL7Qwrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=1)\n",
        "dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "LWLq2a8kQynA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz \n",
        "\n",
        "dot_data = tree.export_graphviz(dt, out_file=None, \n",
        "    feature_names=new_raw_data.drop('Exited', axis=1).columns,    \n",
        "    class_names=new_raw_data['Exited'].unique().astype(str),  \n",
        "    filled=True, rounded=True,  \n",
        "    special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "_tsImgteTgUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, column in enumerate(new_raw_data.drop('Exited', axis=1)):\n",
        "    print('Importance of feature {}:, {:.3f}'.format(column, dt.feature_importances_[i]))\n",
        "    \n",
        "    fi = pd.DataFrame({'Variable': [column], 'Feature Importance Score': [dt.feature_importances_[i]]})\n",
        "    \n",
        "    try:\n",
        "        final_fi = pd.concat([final_fi,fi], ignore_index = True)\n",
        "    except:\n",
        "        final_fi = fi\n",
        "        \n",
        "        \n",
        "# Ordering the data\n",
        "final_fi = final_fi.sort_values('Feature Importance Score', ascending = False).reset_index()            \n",
        "final_fi"
      ],
      "metadata": {
        "id": "ZXk8XFoUTlGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Training Accuracy is:', dt.score(X_train, y_train))\n",
        "print('The Testing Accuracy is:', dt.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "YLtadOEXXAMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
        "    \"\"\"Plots a confusion matrix.\"\"\"\n",
        "    if classes is not None:\n",
        "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':50})\n",
        "    else:\n",
        "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "y_pred = dt.predict(X_train)\n",
        "\n",
        "# Plotting Confusion Matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "cm_norm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm_norm, classes=dt.classes_, title='Training confusion')"
      ],
      "metadata": {
        "id": "NY8zkrmMYELG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "rf.fit(X_train, y_train)\n",
        "prediction_test = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "b3Ephj5sYcFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Training Accuracy is:', rf.score(X_train, y_train))\n",
        "print('The Testing Accuracy is:', rf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "9Lb8a0EUk83Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, prediction_test)\n",
        "cm_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm_norm, classes=rf.classes_)"
      ],
      "metadata": {
        "id": "6Bxy18e5lT0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#пытаемся улучшить нашу модель набором (продуктом) параметров\n",
        "\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "n_estimators = 100\n",
        "max_depth = [None, 2, 3, 4, 5]\n",
        "max_features = [1, 'sqrt', 'log2']\n",
        "\n",
        "\n",
        "for f,d in product(max_features, max_depth):\n",
        "  rf = RandomForestClassifier(n_estimators=n_estimators,\n",
        "                              criterion='entropy',\n",
        "                              max_features=f,\n",
        "                              max_depth=d,\n",
        "                              random_state=1337,\n",
        "                              n_jobs = 2)\n",
        "  rf.fit(X_train, y_train)  \n",
        "  prediction_test = rf.predict(X=X_test)\n",
        "  print('Classification accuracy on test set with max features = {} and max depth = {} : {:.3f}'.format(f,d, accuracy_score(y_test,prediction_test)))\n",
        "  cm = confusion_matrix(y_test,prediction_test)\n",
        "  cm_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "  plt.figure(figsize=(12,10))\n",
        "  plot_confusion_matrix(cm_norm, classes=rf.classes_)\n",
        "  title='Confusion matrix accuracy on test set with max features = {} and max_depth = {}: {:.3f}'.format(f, d, accuracy_score(y_test,prediction_test))"
      ],
      "metadata": {
        "id": "ngDG5K6KlXbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/master/xgboost-1.6.0.dev0%2B1d468e20a4fff83f3149e99371b67e6b31f64152-py3-none-manylinux2014_x86_64.whl"
      ],
      "metadata": {
        "id": "u0nRPsL4hGDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost\n",
        "\n",
        "classifier=xgboost.XGBClassifier(tree_method='gpu_hist')\n",
        "\n",
        "params={\n",
        "    \"learning_rate\":[0.05,0.10,0.15,0.20,0.25,0.30],\n",
        "    \"max_depth\":[2,3,4,5,6,8,10,12,15],\n",
        "    \"min_child_weight\":[1,3,5,7],\n",
        "    \"gamma\":[0.0,0.1,0.2,0.3,0.4],\n",
        "    \"colsample_bytree\":[0.3,0.4,0.5,0.7]}\n",
        "\n",
        "clf =RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',cv=5,verbose=3)\n",
        "# source: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
        "\n",
        "# fitting it\n",
        "clf.fit(X,y)\n",
        "\n",
        "# best parameters\n",
        "# clf.best_params_"
      ],
      "metadata": {
        "id": "FhzIzCetn8gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.best_params_"
      ],
      "metadata": {
        "id": "AV96iyNBoLKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.best_estimator_)"
      ],
      "metadata": {
        "id": "OPEtFgZyoj4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = clf.best_estimator_"
      ],
      "metadata": {
        "id": "-OXru594deB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(X, y)"
      ],
      "metadata": {
        "id": "RyQliTYqdwAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_xgboost = final_model.predict(X)"
      ],
      "metadata": {
        "id": "hl5KavDOd5_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y, pred_xgboost)\n",
        "cm_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure\n",
        "plot_confusion_matrix(cm_norm, classes = rf.classes_)"
      ],
      "metadata": {
        "id": "HdBTzZSuAsSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d71axN9cBNTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}