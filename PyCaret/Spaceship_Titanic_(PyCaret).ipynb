{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spaceship Titanic (PyCaret).ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMtLUtDgTWgbS8FqNgOar7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkurbatovv/Python/blob/main/Spaceship_Titanic_(PyCaret).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvlDGXdDU2tv"
      },
      "outputs": [],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "\n",
        "\n",
        "!mkdir -p ~/.kaggle/\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "es0vliFCU7yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c spaceship-titanic"
      ],
      "metadata": {
        "id": "aqQnqD5nVOBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip spaceship-titanic.zip"
      ],
      "metadata": {
        "id": "10oGJd6XVYpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pycaret.classification import *"
      ],
      "metadata": {
        "id": "l57MjndqVgBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_group_features(df):\n",
        "    \n",
        "    '''\n",
        "    Group level features\n",
        "    - Number of passengers\n",
        "    - Number of VIPs passengers\n",
        "    - Number of passengers in cryosleep\n",
        "    - Number of unique cabins\n",
        "    - Number of unique decks\n",
        "    - Number of unique sides\n",
        "    - Mean age of passengers in the group\n",
        "    - mean spend on various expense area\n",
        "    - mean total spend\n",
        "    - Number of unique home planets\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    df = (df.groupby('PassengerGroup', as_index = False)\n",
        "          .agg({'PassengerNo':'nunique',\n",
        "                'VIP':lambda x: sum(x == True),\n",
        "                'CryoSleep': lambda x: sum(x == True),\n",
        "                'Cabin': 'nunique',\n",
        "                'Deck': 'nunique',\n",
        "                'Side': 'nunique',\n",
        "                'Age': 'mean',\n",
        "                'RoomService': 'mean',\n",
        "                'FoodCourt': 'mean',\n",
        "                'ShoppingMall':'mean',\n",
        "                'Spa':'mean',\n",
        "                'VRDeck': 'mean',\n",
        "                'TotalSpend':'mean',\n",
        "                'HomePlanet': 'nunique'})\n",
        "          .rename(columns = {'PassengerNo':'Count'})\n",
        "         )\n",
        "    \n",
        "    df['PctRoomService'] = df['RoomService']/df['TotalSpend']\n",
        "    df['PctFoodCourt'] = df['FoodCourt']/df['TotalSpend']\n",
        "    df['PctShoppingMall'] = df['ShoppingMall']/df['TotalSpend']\n",
        "    df['PctSpa'] = df['Spa']/df['TotalSpend']\n",
        "    df['PctVRDeck'] = df['VRDeck']/df['TotalSpend']\n",
        "    \n",
        "    fill_cols = ['PctRoomService', 'PctFoodCourt', 'PctShoppingMall', 'PctSpa', 'PctVRDeck']\n",
        "    df[fill_cols] = df[fill_cols].fillna(0)\n",
        "    \n",
        "    df.columns = [f'Group{i}' if i not in ['PassengerGroup'] else i for i in df.columns]\n",
        "    \n",
        "    \n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def create_features(df):\n",
        "    \n",
        "    bool_type = ['VIP', 'CryoSleep']\n",
        "    df[bool_type] = df[bool_type].astype(bool)\n",
        "    \n",
        "    df['PassengerGroup'] = df['PassengerId'].apply(lambda x: x.split('_')[0])\n",
        "    df['PassengerNo'] = df['PassengerId'].apply(lambda x: x.split('_')[1])\n",
        "    df.loc[df['Cabin'].isnull(), 'Cabin'] = 'None/None/None'\n",
        "    \n",
        "    fill_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "    df[fill_cols] = df[fill_cols].fillna(0)\n",
        "    df['TotalSpend'] = df['RoomService'] + df['FoodCourt'] + df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
        "    df['PctRoomService'] = df['RoomService']/df['TotalSpend']\n",
        "    df['PctFoodCourt'] = df['FoodCourt']/df['TotalSpend']\n",
        "    df['PctShoppingMall'] = df['ShoppingMall']/df['TotalSpend']\n",
        "    df['PctSpa'] = df['Spa']/df['TotalSpend']\n",
        "    df['PctVRDeck'] = df['VRDeck']/df['TotalSpend']\n",
        "    fill_cols = ['PctRoomService', 'PctFoodCourt', 'PctShoppingMall', 'PctSpa', 'PctVRDeck']\n",
        "    df[fill_cols] = df[fill_cols].fillna(0)\n",
        "    \n",
        "    df['Age'] = df['Age'].fillna(df.groupby('HomePlanet')['Age'].transform('median'))\n",
        "    df['CryoSleep'] = df['CryoSleep'].fillna(False)\n",
        "    \n",
        "    df['Deck'] = df['Cabin'].apply(lambda x: str(x).split('/')[0])\n",
        "    df['Side'] = df['Cabin'].apply(lambda x: str(x).split('/')[2])\n",
        "    \n",
        "    df_group_features = create_group_features(df)    \n",
        "    \n",
        "    df = pd.merge(df, df_group_features, on = 'PassengerGroup', how = 'left')\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "w6Ee3uZqVmV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "frsH89DIVqOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = create_features(df_train)\n",
        "test = create_features(df_test)"
      ],
      "metadata": {
        "id": "fuSHpCAiVvZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = list(train.select_dtypes('float64').columns) + list(train.select_dtypes('int64').columns) \n",
        "\n",
        "s = setup(data = train,\n",
        "          target = 'Transported',\n",
        "          train_size = 0.99,\n",
        "          fold_strategy = 'stratifiedkfold',\n",
        "          fold = 5,\n",
        "          fold_shuffle = True,\n",
        "          numeric_features = num_cols,\n",
        "          ignore_low_variance=True,\n",
        "          remove_multicollinearity = True,\n",
        "          normalize = True,\n",
        "          normalize_method = 'robust',\n",
        "          data_split_stratify = True,\n",
        "          \n",
        "          ignore_features = ['PassengerNo', 'Name', 'PassengerId', 'PassengerGroup', 'Cabin'],\n",
        "          silent = True)\n",
        "\n",
        "\n",
        "remove_metric('kappa')\n",
        "remove_metric('mcc')"
      ],
      "metadata": {
        "id": "37R6VP9GVyYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = compare_models(n_select = 3)"
      ],
      "metadata": {
        "id": "9Z9fcz9GV0kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best"
      ],
      "metadata": {
        "id": "hWYgQ9rEV6Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blender = blend_models(estimator_list=best)"
      ],
      "metadata": {
        "id": "UBWunuV0WhgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lgb = tune_model(blender)"
      ],
      "metadata": {
        "id": "xN_lTPgCXICt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = predict_model(tuned_lgb, test)\n",
        "df_sub = df_pred.loc[:, ['PassengerId', 'Label']].rename(columns = {'Label':'Transported'})\n",
        "df_sub.to_csv('submission.csv', index = False)"
      ],
      "metadata": {
        "id": "0myb6pZ8XsmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "1Skr3p9XYpLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lExl4FPtZD0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
